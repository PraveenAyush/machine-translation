{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 00:18:21.255957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-02 00:18:22.356906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp as kn\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "# from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "\n",
    "from utils import data_utils, parameters as params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from individual files\n",
    "# data_utils.create_dataset('./data/en-kn/train.en', './data/en-kn/train.kn', 450000, './data/en-kn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and test sets\n",
    "# data_utils.split_data('./data/en-kn/data.tsv', output_dir='./data/en-kn/', val_size=0.2, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Headaches and migraines', 'ತಲೆನೋವು ಮತ್ತು ಮೈಗ್ರೇನ್ ಲಕ್ಷಣಗಳು'],\n",
       " ['Jakhni PO Baraon PS', 'ಜಖನಿ ಪಿಒ ಬಾರನ್ ಪಿಎಸ್'],\n",
       " ['He said that it was very difficult to do that.',\n",
       "  'ಇದು ತೀರಾ ಕಷ್ಟಸಾಧ್ಯ ಎಂದು ಹೇಳಿದರು.'],\n",
       " ['Two rounds remain.', 'ಉಳಿದಿದ್ದು ಎರಡೇ ವಿಕೆಟ್\\u200c.'],\n",
       " ['Double edge', 'ಅವಳಿ ತಿರುಪು.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs = pd.read_csv('./data/en-kn/train.tsv', sep='\\t', header=None).values.tolist()\n",
    "train_pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pairs = pd.read_csv('./data/en-kn/val.tsv', sep='\\t', header=None).values.tolist()\n",
    "len(val_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vocabulary and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    "\n",
    "eng_samples = [pair[0] for pair in train_pairs]\n",
    "# data_utils.compute_vocabulary(eng_samples, params.ENG_VOCAB_SIZE, reserved_tokens=reserved_tokens, vocab_file_path='./utils/en-kn/eng_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_samples = [pair[1] for pair in train_pairs]\n",
    "# data_utils.compute_vocabulary(kan_samples, params.KAN_VOCAB_SIZE, reserved_tokens=reserved_tokens, vocab_file_path='./utils/en-kn/kan_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./utils/en-kn/eng_vocab.txt', 'r') as f, open('./utils/en-kn/kan_vocab.txt', 'r') as g:\n",
    "    eng_vocab = f.read().splitlines()\n",
    "    kan_vocab = g.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size:  14617\n",
      "Kannada vocab size:  14900\n"
     ]
    }
   ],
   "source": [
    "print(\"English vocab size: \", len(eng_vocab))\n",
    "print(\"Kannada vocab size: \", len(kan_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab sample:  ['Mumbai', 'When', 'off', 'wife', 'matter', 'Pradesh', '##es', 'spot', 'last', 'movie']\n",
      "Kannada vocab sample:  ['ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ']\n"
     ]
    }
   ],
   "source": [
    "print(\"English vocab sample: \", eng_vocab[350:360])\n",
    "print(\"Kannada vocab sample: \", kan_vocab[350:360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 00:18:27.153322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:27.301030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:27.301320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:27.302742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:27.303040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:27.303364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:28.826987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:28.827311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:28.827328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-02 00:18:28.827582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-02 00:18:28.827640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2077 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Define the tokenizer\n",
    "eng_tokenizer = kn.tokenizers.WordPieceTokenizer(vocabulary=eng_vocab, lowercase=False)\n",
    "kan_tokenizer = kn.tokenizers.WordPieceTokenizer(vocabulary=kan_vocab, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English input:  The film stars Shanvi Srivastav as the female lead.\n",
      "English tokens:  tf.Tensor(\n",
      "[  103   173  1013 12732   685  7342  1158  1586   126    97  2097   554\n",
      "    17], shape=(13,), dtype=int32)\n",
      "Reconstructed English input:  tf.Tensor(b'The film stars Shanvi Srivastav as the female lead .', shape=(), dtype=string)\n",
      "\n",
      "Kannada input:  ಉಳಿದಂತೆ ಶಾನ್ವಿ ಶ್ರೀವಾತ್ಸವ್ ನಾಯಕಿಯಾಗಿದ್ದಾರೆ.\n",
      "Kannada tokens:  tf.Tensor([5067 1019  561 1079  753 1249 8467  534 4604  660   17], shape=(11,), dtype=int32)\n",
      "Reconstructed Kannada input:  tf.Tensor(b'\\xe0\\xb2\\x89\\xe0\\xb2\\xb3\\xe0\\xb2\\xbf\\xe0\\xb2\\xa6\\xe0\\xb2\\x82\\xe0\\xb2\\xa4\\xe0\\xb3\\x86 \\xe0\\xb2\\xb6\\xe0\\xb2\\xbe\\xe0\\xb2\\xa8\\xe0\\xb3\\x8d\\xe0\\xb2\\xb5\\xe0\\xb2\\xbf \\xe0\\xb2\\xb6\\xe0\\xb3\\x8d\\xe0\\xb2\\xb0\\xe0\\xb3\\x80\\xe0\\xb2\\xb5\\xe0\\xb2\\xbe\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xb8\\xe0\\xb2\\xb5\\xe0\\xb3\\x8d \\xe0\\xb2\\xa8\\xe0\\xb2\\xbe\\xe0\\xb2\\xaf\\xe0\\xb2\\x95\\xe0\\xb2\\xbf\\xe0\\xb2\\xaf\\xe0\\xb2\\xbe\\xe0\\xb2\\x97\\xe0\\xb2\\xbf\\xe0\\xb2\\xa6\\xe0\\xb3\\x8d\\xe0\\xb2\\xa6\\xe0\\xb2\\xbe\\xe0\\xb2\\xb0\\xe0\\xb3\\x86 .', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Testing the tokenizer\n",
    "eng_tokens = eng_tokenizer.tokenize(eng_samples[5])\n",
    "print(\"English input: \", eng_samples[5])\n",
    "print(\"English tokens: \", eng_tokens)\n",
    "print(\"Reconstructed English input: \", eng_tokenizer.detokenize(eng_tokens))\n",
    "\n",
    "print()\n",
    "\n",
    "kan_tokens = kan_tokenizer.tokenize(kan_samples[5])\n",
    "print(\"Kannada input: \", kan_samples[5])\n",
    "print(\"Kannada tokens: \", kan_tokens)\n",
    "print(\"Reconstructed Kannada input: \", kan_tokenizer.detokenize(kan_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ಉಳಿದಂತೆ ಶಾನ್ವಿ ಶ್ರೀವಾತ್ಸವ್ ನಾಯಕಿಯಾಗಿದ್ದಾರೆ .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = kan_tokenizer.detokenize(kan_tokens).numpy().decode('utf-8') # type: ignore\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = data_utils.make_dataset(train_pairs, params.BATCH_SIZE, eng_tokenizer, kan_tokenizer, params.MAX_SEQ_LEN)\n",
    "val_ds = data_utils.make_dataset(val_pairs, params.BATCH_SIZE, eng_tokenizer, kan_tokenizer, params.MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['encoder_inputs'].shape: (48, 40)\n",
      "inputs['decoder_inputs'].shape: (48, 40)\n",
      "targets.shape: (48, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 00:18:34.976628: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['encoder_inputs'].shape: {inputs['encoder_inputs'].shape}\")\n",
    "    print(f\"inputs['decoder_inputs'].shape: {inputs['decoder_inputs'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.layers.Input(shape=(None,), dtype='int64', name='encoder_inputs')\n",
    "\n",
    "# Encoder Embedding \n",
    "x = kn.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=params.ENG_VOCAB_SIZE,\n",
    "    sequence_length=params.MAX_SEQ_LEN,\n",
    "    embedding_dim=params.EMBEDDING_DIM,\n",
    "    mask_zero=True,\n",
    "    name='encoder_embedding'\n",
    ") (encoder_inputs)\n",
    "\n",
    "# Encoder Transformer Block\n",
    "encoder_outputs = kn.layers.TransformerEncoder(intermediate_dim=params.INTERMEDIATE_DIM, num_heads=params.NUM_HEADS, dropout=0.3, name='encoder_transformer_block') (x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs, name='encoder')\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.layers.Input(shape=(None,), dtype='int64', name='decoder_inputs')\n",
    "encoded_seq_inputs = keras.layers.Input(shape=(None, params.EMBEDDING_DIM), name='decoder_attention_inputs')\n",
    "\n",
    "# Decoder Embedding\n",
    "x = kn.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=params.KAN_VOCAB_SIZE,\n",
    "    sequence_length=params.MAX_SEQ_LEN,\n",
    "    embedding_dim=params.EMBEDDING_DIM,\n",
    "    mask_zero=True,\n",
    "    name='decoder_embedding'\n",
    ") (decoder_inputs)\n",
    "\n",
    "# Decoder Transformer Block\n",
    "x = kn.layers.TransformerDecoder(intermediate_dim=params.INTERMEDIATE_DIM, num_heads=params.NUM_HEADS, dropout=0.3, name='decoder_transformer_block') (\n",
    "    decoder_sequence=x, \n",
    "    encoder_sequence=encoded_seq_inputs\n",
    ")\n",
    "x = keras.layers.Dropout(0.5, name='decoder_dropout') (x)\n",
    "\n",
    "# Decoder output\n",
    "decoder_outputs = keras.layers.Dense(params.KAN_VOCAB_SIZE, activation='softmax', name='decoder_outputs') (x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs, name='decoder')\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name='transformer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(transformer, show_shapes=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_embedding (TokenAn  (None, None, 256)            3850240   ['encoder_inputs[0][0]']      \n",
      " dPositionEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_transformer_block   (None, None, 256)            1310964   ['encoder_embedding[0][0]']   \n",
      " (TransformerEncoder)                                                                             \n",
      "                                                                                                  \n",
      " decoder (Functional)        (None, None, 15000)          9275776   ['decoder_inputs[0][0]',      \n",
      "                                                                     'encoder_transformer_block[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14436980 (55.07 MB)\n",
      "Trainable params: 14436980 (55.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history = transformer.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=params.EPOCHS,\n",
    "#     callbacks=[\n",
    "#         # keras.callbacks.ModelCheckpoint('./models/en-kn/transformer_14M_weights.h5', save_best_only=True, save_weights_only=True, verbose=1),\n",
    "#         keras.callbacks.BackupAndRestore('./models/en-kn/backups'),\n",
    "#         keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_embedding (TokenAn  (None, None, 256)            3850240   ['encoder_inputs[0][0]']      \n",
      " dPositionEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_transformer_block_  (None, None, 256)            1310964   ['encoder_embedding[0][0]']   \n",
      " 1 (TransformerEncoder)                                                                           \n",
      "                                                                                                  \n",
      " decoder (Functional)        (None, None, 15000)          9275776   ['decoder_inputs[0][0]',      \n",
      "                                                                     'encoder_transformer_block_1[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14436980 (55.07 MB)\n",
      "Trainable params: 14436980 (55.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer = keras.models.load_model('./models/en-kn/model/')\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29700"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs = pd.read_csv('./data/en-kn/test.tsv', sep='\\t', header=None).values.tolist()\n",
    "len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 00:18:42.334763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x759ab070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-02 00:18:42.334823: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-09-02 00:18:42.603075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-09-02 00:18:42.795423: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-02 00:18:42.901518: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Can India win the series?\n",
      "Translated: ಭಾರತ ತಂಡ ಭಾರತ ಗೆಲುವು ಸಾಧಿಸುವುದು ?\n",
      "\n",
      "Input: These questions intrigued a number of economists.\n",
      "Translated: ಈ ಪ್ರಶ್ನೆಗಳಿಗೆ ಉತ್ತರ ಅರ್ಥಶಾಸ್ತ್ರಜ್ಞರ ಬಗ್ಗೆ ಕುತೂಹಲ ಮೂಡಿಸಿದೆ .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eng_samples = [pair[0] for pair in test_pairs]\n",
    "\n",
    "for i in range(2):\n",
    "    input_sequence = random.choice(test_eng_samples)\n",
    "    translated_sequence = data_utils.decode_sequences(tf.constant([input_sequence]), eng_tokenizer, kan_tokenizer, params.MAX_SEQ_LEN, transformer)\n",
    "    translated_sequence = (\n",
    "        translated_sequence.replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .replace(\"[PAD]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(f\"Input: {input_sequence}\")\n",
    "    print(f\"Translated: {translated_sequence}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = data_utils.make_dataset(test_pairs, params.BATCH_SIZE, eng_tokenizer, kan_tokenizer, params.MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619/619 [==============================] - 30s 47ms/step - loss: 3.4181 - accuracy: 0.4134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4180784225463867, 0.41343721747398376]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.evaluate(test_ds, use_multiprocessing=True, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleu_score = kn.metrics.Bleu(tokenizer=kan_tokenizer, name='bleu', max_order=3)\n",
    "# BLEU score comes to around 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes too long to run\n",
    "# for pair in test_pairs[10000:15000]:\n",
    "#     input_sequence = pair[0]\n",
    "#     reference_sequence = pair[1]\n",
    "\n",
    "#     translated_sequence = data_utils.decode_sequences(tf.constant([input_sequence]), eng_tokenizer, kan_tokenizer, params.MAX_SEQ_LEN, transformer)\n",
    "#     translated_sequence = (\n",
    "#         translated_sequence.replace(\"[START]\", \"\")\n",
    "#         .replace(\"[END]\", \"\")\n",
    "#         .replace(\"[PAD]\", \"\")\n",
    "#         .strip()\n",
    "#     )\n",
    "\n",
    "#     bleu_score.update_state([reference_sequence], [translated_sequence])\n",
    "# print(f\"Bleu score: {bleu_score.result().numpy() * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
